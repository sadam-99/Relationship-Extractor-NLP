{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T09:25:44.309128Z",
     "start_time": "2020-11-18T09:25:40.767350Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.parse.corenlp.CoreNLPParser\u001b[0m instead.'\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import re, sys, nltk\n",
    "from nltk.tokenize.stanford import StanfordTokenizer\n",
    "# path_to_jar = \"/home/shanu/nltk/jars/stanford-postagger.jar\"\n",
    "path_to_jar = \"data/stanford-postagger.jar\"\n",
    "tokenizer = StanfordTokenizer(path_to_jar)\n",
    "import _pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T09:28:18.439941Z",
     "start_time": "2020-11-18T09:28:18.420261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Component-Whole(e2,e1)', 'Other', 'Instrument-Agency(e2,e1)', 'Other', 'Member-Collection(e1,e2)', 'Other', 'Cause-Effect(e2,e1)', 'Entity-Destination(e1,e2)', 'Content-Container(e1,e2)', 'Entity-Destination(e1,e2)', 'Member-Collection(e1,e2)', 'Other', 'Message-Topic(e1,e2)', 'Cause-Effect(e2,e1)', 'Instrument-Agency(e2,e1)', 'Message-Topic(e1,e2)', 'Instrument-Agency(e2,e1)', 'Product-Producer(e2,e1)', 'Component-Whole(e2,e1)', 'Member-Collection(e2,e1)', 'Entity-Origin(e1,e2)', 'Member-Collection(e2,e1)', 'Cause-Effect(e1,e2)', 'Other', 'Member-Collection(e2,e1)', 'Other', 'Cause-Effect(e1,e2)', 'Message-Topic(e1,e2)', 'Message-Topic(e1,e2)', 'Component-Whole(e1,e2)', 'Message-Topic(e2,e1)', 'Cause-Effect(e2,e1)', 'Product-Producer(e1,e2)', 'Entity-Destination(e1,e2)', 'Component-Whole(e1,e2)', 'Entity-Origin(e1,e2)', 'Other', 'Component-Whole(e2,e1)', 'Cause-Effect(e1,e2)', 'Instrument-Agency(e2,e1)']\n"
     ]
    }
   ],
   "source": [
    "# Extracting the Relations \n",
    "# Please comment this when preprocessing the sentences.\n",
    "# for training data open \"TRAIN_FILE.TXT\" and for test data open \"TEST_FILE_FULL.TXT\"\n",
    "\n",
    "lines = []\n",
    "# for line in open(\"data/TRAIN_FILE.TXT\"):\n",
    "for line in open(\"data/TRAIN_Sample.TXT\"):\n",
    "    lines.append(line.strip())\n",
    "\n",
    "relations = []\n",
    "for i, w in enumerate(lines):\n",
    "    if((i+3)%4==0):\n",
    "        relations.append(w)\n",
    "        \n",
    "f = open(\"data/train_relations.txt\", 'w')\n",
    "for rel in relations:\n",
    "    f.write(rel+'\\n')\n",
    "print(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T09:29:06.599510Z",
     "start_time": "2020-11-18T09:29:06.577160Z"
    }
   },
   "outputs": [],
   "source": [
    "# For preprocessing Training data open \"TRAIN_FILE.TXT and for Test data open \"TEST_FILE.txt\n",
    "lines = []\n",
    "# for line in open(\"data/TRAIN_FILE.TXT\"): \n",
    "for line in open(\"data/TRAIN_Sample.TXT\"):\n",
    "    m = re.match(r'^([0-9]+)\\s\"(.+)\"$', line.strip())\n",
    "    if(m is not None):\n",
    "        lines.append(m.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T09:29:08.050106Z",
     "start_time": "2020-11-18T09:29:08.040669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T09:39:25.396895Z",
     "start_time": "2020-11-18T09:39:25.233243Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The system as described above has its greatest application in an arrayed configuration of antenna elements .\n",
      "1 The child was carefully wrapped and bound into the cradle by means of a cord .\n",
      "2 The author of a keygen uses a disassembler to look at the raw assembly code .\n",
      "3 A misty ridge uprises from the surge .\n",
      "4 The student association is the voice of the undergraduate student population of the State University of New York at Buffalo .\n",
      "5 This is the sprawling complex that is Peru 's largest producer of silver .\n",
      "6 The current view is that the chronic inflammation in the distal part of the stomach caused by Helicobacter pylori infection results in an increased acid production from the non-infected upper corpus region of the stomach .\n",
      "7 People have been moving back into downtown .\n",
      "8 The lawsonite was contained in a platinum crucible and the counter-weight was a plastic crucible with metal pieces .\n",
      "9 The solute was placed inside a beaker and 5 mL of the solvent was pipetted into a 25 mL glass flask for each trial .\n",
      "10 The fifty essays collected in this volume testify to most of the prominent themes from Professor Quispel 's scholarly career .\n",
      "11 Their composer has sunk into oblivion .\n",
      "12 The Pulitzer Committee issues an official citation explaining the reasons for the award .\n",
      "13 The burst has been caused by water hammer pressure .\n",
      "14 Even commercial networks have moved into high-definition broadcast .\n",
      "15 It was a friendly call to remind them about the bill and make sure they have a copy of the invoice .\n",
      "16 Texas-born virtuoso finds harmony , sophistication in Appalachian instrument .\n",
      "17 The factory 's products have included flower pots , Finnish rooster-whistles , pans , trays , tea pots , ash trays and air moisturisers .\n",
      "18 The girl showed a photo of apple tree blossom on a fruit tree in the Central Valley .\n",
      "19 They tried an assault of their own an hour later , with two columns of sixteen tanks backed by a battalion of Panzer grenadiers .\n",
      "20 Their knowledge of the power and rank symbols of the Continental empires was gained from the numerous Germanic recruits in the Roman army , and from the Roman practice of enfeoffing various Germanic warrior groups with land in the imperial provinces .\n",
      "21 She soon had a stable of her own rescued hounds .\n",
      "22 The singer , who performed three of the nominated songs , also caused a commotion on the red carpet .\n",
      "23 His intellectually engaging books and essays remain pertinent to illuminating contemporary history .\n",
      "24 Poor hygiene controls , reports of a brace of gamey grouse and what looked like a skinned fox all amounted to a pie that was unfit for human consumption .\n",
      "25 This sweet dress is made with a blend of cotton and silk , and the crochet flower necklace is the perfect accessory .\n",
      "26 Suicide is one of the leading causes of death among pre-adolescents and teens , and victims of bullying are at an increased risk for committing suicide .\n",
      "27 This article gives details on 2004 in music in the United Kingdom , including the official charts from that year .\n",
      "28 We have therefore taken the initiative to convene the first international open meeting dedicated solely to rural history .\n",
      "29 The timer of the device automatically eliminates wasted `` standby power '' consumption by automatically turn off electronics plugged into the `` auto off '' outlets .\n",
      "30 Bob Parks made a similar offer in a phone call made earlier this week .\n",
      "31 He had chest pains and headaches from mold in the bedrooms .\n",
      "32 The silver-haired author was not just laying India 's politician saint to rest but healing a generations-old rift in the family of the country 's founding father .\n",
      "33 It describes a method for loading a horizontal stack of containers into a carton .\n",
      "34 The Foundation decided to repurpose the building in order to reduce wear and tear on the plumbing in the manor house by redirecting visitors during restoration projects and beyond .\n",
      "35 The technology is available to produce and transmit electricity economically from OTEC systems .\n",
      "36 The Medicare buy-in plan ran into Senate resistance .\n",
      "37 The provinces are divided into counties ( shahrestan ) , and subdivided into districts ( bakhsh ) and sub-districts ( dehestan ) .\n",
      "38 Financial stress is one of the main causes of divorce .\n",
      "39 Newspapers swap content via widgets with the help of the newsgator service .\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "e1 = []\n",
    "e2 = []\n",
    "for j,line in enumerate(lines):\n",
    "    text = []\n",
    "    temp = []\n",
    "    t = line.split(\"<e1>\")\n",
    "    text.append(t[0])\n",
    "    temp.append(t[0])\n",
    "\n",
    "    t = t[1].split(\"</e1>\")\n",
    "    e1_text = text\n",
    "    e1_text = \" \".join(e1_text)\n",
    "#     e1_text = tokenizer.tokenize(e1_text)\n",
    "    e1_text = nltk.word_tokenize(e1_text)\n",
    "    text.append(t[0])\n",
    "    e11= t[0]\n",
    "#     y = tokenizer.tokenize(t[0])\n",
    "    y = nltk.word_tokenize(t[0])\n",
    "    y[0] +=\"E11\"\n",
    "    temp.append(\" \".join(y))\n",
    "    t = t[1].split(\"<e2>\")\n",
    "    text.append(t[0])\n",
    "    temp.append(t[0])\n",
    "    t = t[1].split(\"</e2>\")\n",
    "    e22 = t[0]\n",
    "    e2_text = text\n",
    "    e2_text = \" \".join(e2_text)\n",
    "#     e2_text = tokenizer.tokenize(e2_text)\n",
    "    e2_text = nltk.word_tokenize(e2_text)\n",
    "    text.append(t[0])\n",
    "    text.append(t[1])\n",
    "#     y = tokenizer.tokenize(t[0])\n",
    "    y = nltk.word_tokenize(t[0])\n",
    "    y[0] +=\"E22\"\n",
    "    temp.append(\" \".join(y))\n",
    "    temp.append(t[1])\n",
    "\n",
    "    text = \" \".join(text)\n",
    "#     text = tokenizer.tokenize(text)\n",
    "    text = nltk.word_tokenize(text)\n",
    "    temp = \" \".join(temp)\n",
    "#     temp = tokenizer.tokenize(temp)\n",
    "    temp = nltk.word_tokenize(temp)\n",
    "\n",
    "#     q1 = tokenizer.tokenize(e11)[0]\n",
    "    q1 = nltk.word_tokenize(e11)[0]\n",
    "#     q2 = tokenizer.tokenize(e22)[0]\n",
    "    q2 = nltk.word_tokenize(e22)[0]\n",
    "    for i, word in enumerate(text):\n",
    "        if(word.find(q1)!=-1):\n",
    "            if(temp[i].find(\"E11\")!=-1):\n",
    "                e1.append(i)            \n",
    "                break\n",
    "    for i, word in enumerate(text):\n",
    "        if(word.find(q2)!=-1):\n",
    "                if(temp[i].find(\"E22\")!=-1):\n",
    "                    e2.append(i)   \n",
    "    text = \" \".join(text)\n",
    "    sentences.append(text)\n",
    "    print(j, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T09:42:15.550137Z",
     "start_time": "2020-11-18T09:42:15.544942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 9, 7, 6, 2, 10, 19, 6, 6, 20, 6, 5, 9, 8, 6, 10, 8, 14, 8, 23, 18, 9, 14, 11, 10, 7, 8, 7, 16, 4, 8, 7, 26, 13, 19, 12, 7, 5, 9, 11]\n"
     ]
    }
   ],
   "source": [
    "# print(sentences)\n",
    "# print(e1)\n",
    "print(e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T09:42:20.650354Z",
     "start_time": "2020-11-18T09:42:20.628605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 40)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences), len(e1), len(e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T09:42:28.700848Z",
     "start_time": "2020-11-18T09:42:28.691321Z"
    }
   },
   "outputs": [],
   "source": [
    "# for saving training data open \"train_data\" and for test data open \"test_data\"\n",
    "\n",
    "with open('data/train_data', 'wb') as f:\n",
    "    pickle.dump((sentences, e1, e2), f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
